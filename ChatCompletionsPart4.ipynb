{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Completions Part 4\n",
    "\n",
    "Make sure you have an environment variable called OPENAI_API_KEY set with your API key.\n",
    "\n",
    "## logprobs (boolean or null)\n",
    "Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the content of message.\n",
    "\n",
    "Here's the revised text without the highlighting around the word \"logprobs\":\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "Log probabilities are instrumental in enhancing the functionality and reliability of large language models across a variety of scenarios. Below is a detailed explanation of their use cases:\n",
    "\n",
    "### Classification Tasks\n",
    "Log probabilities are extremely valuable in classification tasks like categorizing news headlines or identifying sentiments within texts. They provide the log probability for each potential category, allowing developers to assess the model's confidence in its classifications. This information can be leveraged to set thresholds for accepting predictions or deciding when further review is necessary, thus enhancing both the reliability and accuracy of automated systems.\n",
    "\n",
    "### Retrieval (Q&A) Evaluation\n",
    "In question-answering systems, log probabilities measure the confidence level of the answers provided. This helps determine the relevance and correctness of the answers, minimizing errors and preventing the model from presenting incorrect information when the context isn't sufficiently clear.\n",
    "\n",
    "### Autocomplete\n",
    "In autocomplete systems, such as those used in search engines or text editors, log probabilities enable the system to suggest the most likely completions by analyzing the log probabilities of different continuations as a user types, thus enhancing the user experience by making typing faster and more precise.\n",
    "\n",
    "### Token Highlighting and Outputting Bytes\n",
    "Log probabilities aid in token highlighting by showing which tokens the model considers most probable, thereby helping in text analysis or debugging of model outputs. The bytes parameter is crucial for accurately reproducing texts with special characters or emojis, ensuring correct display across different platforms.\n",
    "\n",
    "### Calculating Perplexity\n",
    "Perplexity, calculated using the log probabilities of the tokens generated by the model, is a measure of the model's certainty about its output. Lower perplexity indicates higher confidence. This metric is vital for comparing model performances across various tasks or configurations.\n",
    "\n",
    "### Moderation\n",
    "Log probabilities support moderation efforts by identifying high-probability words or phrases that match known patterns of inappropriate content, enabling automated filtering of harmful language.\n",
    "\n",
    "### Keyword Selection\n",
    "In content generation and SEO, log probabilities assist in selecting keywords that are most likely to enhance the visibility of web content, allowing marketers to optimize their content more effectively.\n",
    "\n",
    "### Improving Prompts and Interpretability of Outputs\n",
    "Log probabilities provide insights into how different prompts affect the likelihood of various responses, which is crucial for refining interactions and designing more effective prompts.\n",
    "\n",
    "### Token Healing\n",
    "In text correction or \"token healing,\" log probabilities help identify and replace unlikely tokens or phrases with more probable alternatives, thus improving the grammatical correctness or coherence of the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expansive mystery.\n"
     ]
    }
   ],
   "source": [
    "# normal chat example without logprob data\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    messages=[ \n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Use two words to describe the universe.\"}\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=256,\n",
    "    stop=None,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expansive mystery.\n",
      "\n",
      "\n",
      "\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Exp', bytes=[69, 120, 112], logprob=-2.120557, top_logprobs=[]), ChatCompletionTokenLogprob(token='ans', bytes=[97, 110, 115], logprob=-0.000444374, top_logprobs=[]), ChatCompletionTokenLogprob(token='ive', bytes=[105, 118, 101], logprob=-1.18755715e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' mystery', bytes=[32, 109, 121, 115, 116, 101, 114, 121], logprob=-0.2989575, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.15134661, top_logprobs=[])])\n",
      "\n",
      "\n",
      "\n",
      "Exp\n",
      "-2.120557\n",
      "12.00%\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# chat example with extracting one set of logprob data\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    messages=[ \n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Use two words to describe the universe.\"}\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=256,\n",
    "    stop=None,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    logprobs=True,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n",
    "print(\"\\n\\n\")\n",
    "print(completion.choices[0].logprobs)\n",
    "print(\"\\n\\n\")\n",
    "print(completion.choices[0].logprobs.content[0].token)\n",
    "print(completion.choices[0].logprobs.content[0].logprob)\n",
    "\n",
    "# calculating the probability of the token\n",
    "probability = np.round(np.exp(completion.choices[0].logprobs.content[0].logprob)*100,2)\n",
    "message = f\"{probability}%\" if probability < 0.01 else f\"{probability:.2f}%\"\n",
    "print(message)\n",
    "print(\"\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Infinitely vast.\n",
      "\n",
      "Token probabilities:\n",
      "\n",
      "Token: Inf, Logprob: -2.0300112, Probability: 13.13%\n",
      "Token: initely, Logprob: -1.3856493e-06, Probability: 100.00%\n",
      "Token:  vast, Logprob: -0.7190319, Probability: 48.72%\n",
      "Token: ., Logprob: -0.9741263, Probability: 37.75%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the client\n",
    "client = OpenAI()\n",
    "\n",
    "# Create a chat completion request\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    messages=[ \n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Use two words to describe the universe.\"}\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=256,\n",
    "    stop=None,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    logprobs=True,\n",
    ")\n",
    "\n",
    "# Retrieve the response\n",
    "response = completion.choices[0].message.content\n",
    "logprobs = completion.choices[0].logprobs\n",
    "\n",
    "print(\"Response:\", response)\n",
    "print(\"\\nToken probabilities:\\n\")\n",
    "\n",
    "# Iterate through each token logprob entry\n",
    "for current_logprob in logprobs.content:\n",
    "    token = current_logprob.token\n",
    "    logprob = current_logprob.logprob\n",
    "    probability = np.round(np.exp(logprob) * 100, 2)\n",
    "    message = f\"{probability}%\" if probability < 0.01 else f\"{probability:.2f}%\"\n",
    "    print(f\"Token: {token}, Logprob: {logprob}, Probability: {message}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## top_logprobs \n",
    "An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. logprobs must be set to true if this parameter is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vast, mysterious\n",
      "\n",
      "\n",
      "\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='V', bytes=[86], logprob=-0.45684347, top_logprobs=[TopLogprob(token='V', bytes=[86], logprob=-0.45684347), TopLogprob(token='Inf', bytes=[73, 110, 102], logprob=-1.6443435)]), ChatCompletionTokenLogprob(token='ast', bytes=[97, 115, 116], logprob=0.0, top_logprobs=[TopLogprob(token='ast', bytes=[97, 115, 116], logprob=0.0), TopLogprob(token='as', bytes=[97, 115], logprob=-18.3125)]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-1.3542051, top_logprobs=[TopLogprob(token=' mystery', bytes=[32, 109, 121, 115, 116, 101, 114, 121], logprob=-0.41670513), TopLogprob(token=',', bytes=[44], logprob=-1.3542051)]), ChatCompletionTokenLogprob(token=' mysterious', bytes=[32, 109, 121, 115, 116, 101, 114, 105, 111, 117, 115], logprob=-0.014296548, top_logprobs=[TopLogprob(token=' mysterious', bytes=[32, 109, 121, 115, 116, 101, 114, 105, 111, 117, 115], logprob=-0.014296548), TopLogprob(token=' M', bytes=[32, 77], logprob=-4.4830465)])])\n",
      "\n",
      "\n",
      "\n",
      "V\n",
      "-0.45684347\n",
      "63.33%\n",
      "\n",
      "\n",
      "Inf\n",
      "-1.6443435\n",
      "19.31%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# chat example with extracting one set of logprob data\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    messages=[ \n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Use two words to describe the universe.\"}\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=256,\n",
    "    stop=None,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    logprobs=True,\n",
    "    top_logprobs=2,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n",
    "print(\"\\n\\n\")\n",
    "print(completion.choices[0].logprobs)\n",
    "print(\"\\n\\n\")\n",
    "print(completion.choices[0].logprobs.content[0].top_logprobs[0].token)\n",
    "print(completion.choices[0].logprobs.content[0].top_logprobs[0].logprob)\n",
    "# calculating the probability of the token\n",
    "probability = np.round(np.exp(completion.choices[0].logprobs.content[0].top_logprobs[0].logprob)*100,2)\n",
    "message = f\"{probability}%\" if probability < 0.01 else f\"{probability:.2f}%\"\n",
    "print(message)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(completion.choices[0].logprobs.content[0].top_logprobs[1].token)\n",
    "print(completion.choices[0].logprobs.content[0].top_logprobs[1].logprob)\n",
    "# calculating the probability of the token\n",
    "probability = np.round(np.exp(completion.choices[0].logprobs.content[0].top_logprobs[1].logprob)*100,2)\n",
    "message = f\"{probability}%\" if probability < 0.01 else f\"{probability:.2f}%\"\n",
    "print(message)\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vast mystery.\n",
      "\n",
      "\n",
      "\n",
      "Token: V\n",
      "Top Logprobs:\n",
      "  V: -0.45684347\n",
      "  Probability: 63.33%\n",
      "  Inf: -1.6443435\n",
      "  Probability: 19.31%\n",
      "  Exp: -2.3005934\n",
      "  Probability: 10.02%\n",
      "  In: -2.7068434\n",
      "  Probability: 6.67%\n",
      "  End: -6.1443434\n",
      "  Probability: 0.21%\n",
      "\n",
      "\n",
      "Token: ast\n",
      "Top Logprobs:\n",
      "  ast: 0.0\n",
      "  Probability: 100.0%\n",
      "  as: -18.328125\n",
      "  Probability: 0.0%\n",
      "  AST: -18.765625\n",
      "  Probability: 0.0%\n",
      "   ast: -21.3125\n",
      "  Probability: 0.0%\n",
      "  aste: -22.609375\n",
      "  Probability: 0.0%\n",
      "\n",
      "\n",
      "Token:  mystery\n",
      "Top Logprobs:\n",
      "   mystery: -0.4577507\n",
      "  Probability: 63.27%\n",
      "  ,: -1.2702507\n",
      "  Probability: 28.08%\n",
      "   Mystery: -3.1765008\n",
      "  Probability: 4.17%\n",
      "  ly: -4.020251\n",
      "  Probability: 1.79%\n",
      "  .: -4.364001\n",
      "  Probability: 1.27%\n",
      "\n",
      "\n",
      "Token: .\n",
      "Top Logprobs:\n",
      "  <|end|>: -0.49822634\n",
      "  Probability: 60.76%\n",
      "  .: -0.93572634\n",
      "  Probability: 39.23%\n",
      "  <|end|>: -9.716976\n",
      "  Probability: 0.01%\n",
      "   : -10.451351\n",
      "  Probability: 0.0%\n",
      "  .\n",
      ": -13.420101\n",
      "  Probability: 0.0%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Create a chat completion request\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    messages=[ \n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Use two words to describe the universe.\"}\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=256,\n",
    "    stop=None,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    logprobs=True,\n",
    "    top_logprobs=5,  # Change this to fetch all top logprobs\n",
    ")\n",
    "\n",
    "# Print the resulting message\n",
    "print(completion.choices[0].message.content)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Loop through each token logprob and print all the top logprobs for each token\n",
    "for token_logprob in completion.choices[0].logprobs.content:\n",
    "    print(f\"Token: {token_logprob.token}\")\n",
    "    print(\"Top Logprobs:\")\n",
    "    for top_logprob in token_logprob.top_logprobs:\n",
    "        print(f\"  {top_logprob.token}: {top_logprob.logprob}\")\n",
    "        probability = np.round(np.exp(top_logprob.logprob)*100,2)\n",
    "        print(f\"  Probability: {probability}%\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Confidence with Logprobs\n",
    "Let's say we want to create a system to classify news articles into a set of pre-defined categories. Without logprobs, we can use Chat Completions to do this, but it is much more difficult to assess the certainty with which the model made its classifications.\n",
    "\n",
    "Now, with logprobs enabled, we can see exactly how confident the model is in its predictions, which is crucial for creating an accurate and trustworthy classifier. For example, if the log probability for the chosen category is high, this suggests the model is quite confident in its classification. If it's low, this suggests the model is less confident. This can be particularly useful in cases where the model's classification is not what you expected, or when the model's output needs to be reviewed or validated by a human."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up our variables\n",
    "CLASSIFICATION_PROMPT = \"\"\"You will be given a headline of a news article.\n",
    "Classify the article into one of the following categories: Technology, Politics, Sports, and Art.\n",
    "Return only the name of the category, and nothing else.\n",
    "MAKE SURE your output is one of the four categories stated.\"\"\"\n",
    "\n",
    "headlines = [\n",
    "    \"Tech Giant Unveils Latest Smartphone Model with Advanced Photo-Editing Features.\",\n",
    "    \"Local Mayor Launches Initiative to Enhance Urban Public Transport.\",\n",
    "    \"Tennis Champion Showcases Hidden Talents in Symphony Orchestra Debut\",\n",
    "    \"Local Artist Wins Prestigious Award for Creating a Robot to Paint Abstract Artwork.\",\n",
    "    \"Startup Develops New App to Help Grassroots Campaigns Increase Voter Engagement\",\n",
    "    \"Former Football Star Elected Mayor Promises to Revitalize City's Public Spaces with Innovative Designs\",\n",
    "    \"Tech Conference Features Interactive Exhibit on the Evolution of Digital Art\",\n",
    "    \"University Research Team Uses AI to Analyze Historical Election Strategies\",\n",
    "    \"Documentary on the Intersection of Sports and Art Premieres at International Film Festival\",\n",
    "    \"Politician’s Controversial Tweet About National Team Selection Sparks Debate\",\n",
    "    \"Emerging Technologies Take Center Stage at Annual Sports Science Symposium\",\n",
    "    \"Biotech Firm Collaborates with Art Institute to Explore Genetic Bases of Creativity\",\n",
    "    \"Famous Artist and Soccer Star Collaborate on a Series of Political Graffiti Murals\",\n",
    "    \"Silicon Valley and Hollywood Unite to Develop a Virtual Reality Series About Ancient Olympic Games\",\n",
    "    \"Government Funds New Technology for Online Platforms to Boost Civic Engagement in Local Communities\",\n",
    "    \"Major Tech Company Accused of Influencing Political Elections Through Social Media Algorithms\",\n",
    "    \"Renowned Sculptor Uses Recycled Electronics to Create Art Commenting on E-waste\",\n",
    "    \"International Summit Discusses the Role of Sports in Promoting Global Peace and Politics\",\n",
    "    \"Activists Use Sports Events as Platforms for Artistic Performances Highlighting Social Issues\",\n",
    "    \"New Study Shows How Digital Platforms Can Enhance Art Education in Schools\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Headline: Tech Giant Unveils Latest Smartphone Model with Advanced Photo-Editing Features.\n",
      "Category: Technology\n",
      "\n",
      "\n",
      "Headline: Local Mayor Launches Initiative to Enhance Urban Public Transport.\n",
      "Category: Politics\n",
      "\n",
      "\n",
      "Headline: Tennis Champion Showcases Hidden Talents in Symphony Orchestra Debut\n",
      "Category: Art\n",
      "\n",
      "\n",
      "Headline: Local Artist Wins Prestigious Award for Creating a Robot to Paint Abstract Artwork.\n",
      "Category: Art\n",
      "\n",
      "\n",
      "Headline: Startup Develops New App to Help Grassroots Campaigns Increase Voter Engagement\n",
      "Category: Technology\n",
      "\n",
      "\n",
      "Headline: Former Football Star Elected Mayor Promises to Revitalize City's Public Spaces with Innovative Designs\n",
      "Category: Politics\n",
      "\n",
      "\n",
      "Headline: Tech Conference Features Interactive Exhibit on the Evolution of Digital Art\n",
      "Category: Art\n",
      "\n",
      "\n",
      "Headline: University Research Team Uses AI to Analyze Historical Election Strategies\n",
      "Category: Technology\n",
      "\n",
      "\n",
      "Headline: Documentary on the Intersection of Sports and Art Premieres at International Film Festival\n",
      "Category: Art\n",
      "\n",
      "\n",
      "Headline: Politician’s Controversial Tweet About National Team Selection Sparks Debate\n",
      "Category: Politics\n",
      "\n",
      "\n",
      "Headline: Emerging Technologies Take Center Stage at Annual Sports Science Symposium\n",
      "Category: Technology\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# normal loop through the headlines with categorization\n",
    "for headline in headlines:\n",
    "    print(f\"\\nHeadline: {headline}\")\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    messages=[ \n",
    "        {\"role\": \"system\", \"content\": CLASSIFICATION_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": f\"Headline: {headline}\"},\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=256,\n",
    "    stop=None,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    logprobs=True,\n",
    "    )\n",
    "    \n",
    "    print(f\"Category: {completion.choices[0].message.content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Headline: Tech Giant Unveils Latest Smartphone Model with Advanced Photo-Editing Features.\n",
      "Technology\n",
      "First token: Technology\n",
      "Logprob of first token: -1.9361265e-07\n",
      "Probability of first token: 100.00%\n",
      "\n",
      "Headline: Local Mayor Launches Initiative to Enhance Urban Public Transport.\n",
      "Politics\n",
      "First token: Politics\n",
      "Logprob of first token: -4.365741e-06\n",
      "Probability of first token: 100.00%\n",
      "\n",
      "Headline: Tennis Champion Showcases Hidden Talents in Symphony Orchestra Debut\n",
      "Art\n",
      "First token: Art\n",
      "Logprob of first token: -1.3856493e-06\n",
      "Probability of first token: 100.00%\n",
      "\n",
      "Headline: Local Artist Wins Prestigious Award for Creating a Robot to Paint Abstract Artwork.\n",
      "Art\n",
      "First token: Art\n",
      "Logprob of first token: -0.012509655\n",
      "Probability of first token: 98.76%\n",
      "\n",
      "Headline: Startup Develops New App to Help Grassroots Campaigns Increase Voter Engagement\n",
      "Technology\n",
      "First token: Technology\n",
      "Logprob of first token: -1.0537016\n",
      "Probability of first token: 34.86%\n",
      "\n",
      "Headline: Former Football Star Elected Mayor Promises to Revitalize City's Public Spaces with Innovative Designs\n",
      "Politics\n",
      "First token: Politics\n",
      "Logprob of first token: -3.202099e-05\n",
      "Probability of first token: 100.00%\n",
      "\n",
      "Headline: Tech Conference Features Interactive Exhibit on the Evolution of Digital Art\n",
      "Art\n",
      "First token: Art\n",
      "Logprob of first token: -0.0027188067\n",
      "Probability of first token: 99.73%\n",
      "\n",
      "Headline: University Research Team Uses AI to Analyze Historical Election Strategies\n",
      "Technology\n",
      "First token: Technology\n",
      "Logprob of first token: -0.010381939\n",
      "Probability of first token: 98.97%\n",
      "\n",
      "Headline: Documentary on the Intersection of Sports and Art Premieres at International Film Festival\n",
      "Art\n",
      "First token: Art\n",
      "Logprob of first token: -2.0935051e-05\n",
      "Probability of first token: 100.00%\n",
      "\n",
      "Headline: Politician’s Controversial Tweet About National Team Selection Sparks Debate\n",
      "Politics\n",
      "First token: Politics\n",
      "Logprob of first token: -0.00014895246\n",
      "Probability of first token: 99.99%\n",
      "\n",
      "Headline: Emerging Technologies Take Center Stage at Annual Sports Science Symposium\n",
      "Technology\n",
      "First token: Technology\n",
      "Logprob of first token: -0.00048811073\n",
      "Probability of first token: 99.95%\n",
      "\n",
      "Headline: Biotech Firm Collaborates with Art Institute to Explore Genetic Bases of Creativity\n",
      "Art\n",
      "First token: Art\n",
      "Logprob of first token: -0.1697278\n",
      "Probability of first token: 84.39%\n",
      "\n",
      "Headline: Famous Artist and Soccer Star Collaborate on a Series of Political Graffiti Murals\n",
      "Art\n",
      "First token: Art\n",
      "Logprob of first token: -6.9882217e-06\n",
      "Probability of first token: 100.00%\n",
      "\n",
      "Headline: Silicon Valley and Hollywood Unite to Develop a Virtual Reality Series About Ancient Olympic Games\n",
      "Technology\n",
      "First token: Technology\n",
      "Logprob of first token: -0.078891434\n",
      "Probability of first token: 92.41%\n",
      "\n",
      "Headline: Government Funds New Technology for Online Platforms to Boost Civic Engagement in Local Communities\n",
      "Technology\n",
      "First token: Technology\n",
      "Logprob of first token: -0.001456186\n",
      "Probability of first token: 99.85%\n",
      "\n",
      "Headline: Major Tech Company Accused of Influencing Political Elections Through Social Media Algorithms\n",
      "Technology\n",
      "First token: Technology\n",
      "Logprob of first token: -0.33045906\n",
      "Probability of first token: 71.86%\n",
      "\n",
      "Headline: Renowned Sculptor Uses Recycled Electronics to Create Art Commenting on E-waste\n",
      "Art\n",
      "First token: Art\n",
      "Logprob of first token: -5.5122365e-07\n",
      "Probability of first token: 100.00%\n",
      "\n",
      "Headline: International Summit Discusses the Role of Sports in Promoting Global Peace and Politics\n",
      "Politics\n",
      "First token: Politics\n",
      "Logprob of first token: -0.37695417\n",
      "Probability of first token: 68.59%\n",
      "\n",
      "Headline: Activists Use Sports Events as Platforms for Artistic Performances Highlighting Social Issues\n",
      "Art\n",
      "First token: Art\n",
      "Logprob of first token: -0.07432386\n",
      "Probability of first token: 92.84%\n",
      "\n",
      "Headline: New Study Shows How Digital Platforms Can Enhance Art Education in Schools\n",
      "Art\n",
      "First token: Art\n",
      "Logprob of first token: -0.23835652\n",
      "Probability of first token: 78.79%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for headline in headlines:\n",
    "    print(f\"\\nHeadline: {headline}\")\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        messages=[ \n",
    "            {\"role\": \"system\", \"content\": CLASSIFICATION_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": headline},\n",
    "        ],\n",
    "        temperature=1,\n",
    "        max_tokens=256,\n",
    "        stop=None,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        logprobs=True\n",
    "    )\n",
    "    \n",
    "    response_content = completion.choices[0].message.content\n",
    "    first_token = completion.choices[0].logprobs.content[0].token\n",
    "    first_token_logprob = completion.choices[0].logprobs.content[0].logprob\n",
    "    \n",
    "    print(response_content)\n",
    "    print(f\"First token: {first_token}\")\n",
    "    print(f\"Logprob of first token: {first_token_logprob}\")\n",
    "\n",
    "    # Calculating the probability of the token\n",
    "    probability = np.exp(first_token_logprob) * 100\n",
    "    formatted_probability = f\"{probability:.2f}%\" if probability < 0.01 else f\"{probability:.2f}%\"\n",
    "    print(f\"Probability of first token: {formatted_probability}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
