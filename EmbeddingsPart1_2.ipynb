{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Part 1\n",
    "OpenAIâ€™s text embeddings measure the relatedness of text strings. \n",
    "\n",
    "Embeddings are commonly used for:\n",
    "- Search (where results are ranked by relevance to a query string)\n",
    "- Clustering (where text strings are grouped by similarity)\n",
    "- Recommendations (where items with related text strings are recommended)\n",
    "- Anomaly detection (where outliers with little relatedness are identified)\n",
    "- Diversity measurement (where similarity distributions are analyzed)\n",
    "- Classification (where text strings are classified by their most similar label)\n",
    "\n",
    "An embedding is a vector (list) of floating point numbers. The distance between two vectors measures their relatedness. Small distances suggest high relatedness and large distances suggest low relatedness.\n",
    "\n",
    "## Getting A Simple Embedding\n",
    "To get an embedding, send your text string to the embeddings API endpoint along with the embedding model name. The response will contain an embedding (list of floating point numbers), which you can extract, save in a vector database, and use for many different use cases.\n",
    "\n",
    "By default, the length of the embedding vector will be 1536 for text-embedding-3-small or 3072 for text-embedding-3-large. You can reduce the dimensions of the embedding by passing in the dimensions parameter without the embedding losing its concept-representing properties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "First fifty dimensions of the embedding: [0.052373871207237244, 0.008488261140882969, -0.028862453997135162, 0.037338875234127045, -0.058482576161623, -0.019699394702911377, 0.0443236380815506, 0.01948630064725876, -0.002975922543555498, -0.035231608897447586, 0.0030099586583673954, 0.00332072121091187, -0.016278045251965523, -0.009672118350863457, 0.005025476682931185, 0.02154621295630932, 0.004335879348218441, 0.020551772788167, 0.002802783390507102, 0.04226372390985489, 0.04635987430810928, 0.023298323154449463, 0.01241866871714592, 0.024363793432712555, 0.03558676689863205, -0.004063591826707125, 0.01602943427860737, 0.0005356956971809268, -0.009979921393096447, -0.020563609898090363, 0.03184577450156212, -0.02355877123773098, 0.018645761534571648, 0.010802702978253365, 0.009524136781692505, -0.016834458336234093, -0.008547453209757805, -0.0051882569678127766, -0.001015158137306571, 0.01080862246453762, 0.0394461415708065, -0.0039156097918748856, 0.0007025456288829446, 0.03051985427737236, 0.0323193185031414, -0.01647930033504963, -0.031940486282110214, 0.005756508558988571, -0.001941526890732348, 0.04609942436218262]\n",
      "Total number of dimensions in the embedding: 1536\n",
      "========================================\n",
      "\n",
      "\n",
      "First fifty dimensions of the embedding: [-0.009912644512951374, -0.024115730077028275, 0.007796219550073147, 0.005413441453129053, 0.011122030206024647, 0.0045100012794137, -0.004661174491047859, -0.03461147099733353, 0.006950369104743004, 0.04921048507094383, -0.047022074460983276, 0.022891946136951447, -0.046302199363708496, 0.026116974651813507, 0.0147141944617033, -0.014620610512793064, -0.002013843273743987, -0.013670379295945168, -0.004103273153305054, -0.015923580154776573, 0.006939570885151625, 0.013627186417579651, 0.03904588520526886, 0.04333632439374924, 0.0277582835406065, 0.01768006943166256, -0.012439397163689137, 0.006453657057136297, -0.027743887156248093, -0.005586210638284683, -0.024677230045199394, 0.04679171368479729, 0.015822798013687134, -0.014347059652209282, -0.038729142397642136, 0.010675709694623947, 0.024504460394382477, -0.0179104283452034, -0.008933617733418941, -0.013951129280030727, 0.02281995862722397, 0.026880040764808655, -0.015491656959056854, 0.01837114617228508, 0.01012140791863203, 0.02640492469072342, 0.002618536353111267, 0.01593797840178013, -0.049296870827674866, 0.035244960337877274]\n",
      "Total number of dimensions in the embedding: 3072\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Create an embedding for the word \"Mary\" using the text-embedding-3-small model\n",
    "response_small = client.embeddings.create(\n",
    "    input=\"Mary\",\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "# capture the embedding from the response\n",
    "embedding_small = response_small.data[0].embedding\n",
    "\n",
    "# Print the first five elements\n",
    "print(\"========================================\")\n",
    "print(\"First fifty dimensions of the embedding:\", embedding_small[:50])\n",
    "\n",
    "# Get the count of all elements in the list\n",
    "count_small = len(embedding_small)\n",
    "print(\"Total number of dimensions in the embedding:\", count_small)\n",
    "print(\"========================================\\n\\n\")\n",
    "\n",
    "# Create an embedding for the word \"Mary\" using the text-embedding-3-large model\n",
    "response_large = client.embeddings.create(\n",
    "    input=\"Mary\",\n",
    "    model=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "# Capture the embedding from the response\n",
    "embedding_large = response_large.data[0].embedding\n",
    "\n",
    "# Print the first five elements\n",
    "print(\"First fifty dimensions of the embedding:\", embedding_large[:50])\n",
    "\n",
    "# Get the count of all elements in the list\n",
    "count_large = len(embedding_large)\n",
    "print(\"Total number of dimensions in the embedding:\", count_large)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Part 2\n",
    "## input (string or array)\n",
    "Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for text-embedding-ada-002), cannot be an empty string, and any array must be 2048 dimensions or less. \n",
    "\n",
    "## model (string)\n",
    "ID of the model to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "First five dimensions of embedding 1: [0.052373871207237244, 0.008488261140882969, -0.028862453997135162, 0.037338875234127045, -0.058482576161623]\n",
      "First five dimensions of embedding 2: [-0.016156574711203575, -0.00031287362799048424, 0.01228250004351139, 0.018016131594777107, 0.056595176458358765]\n",
      "First five dimensions of embedding 3: [0.026696905493736267, 0.008715566247701645, -0.009066421538591385, 0.026457685977220535, -0.014456836506724358]\n",
      "First five dimensions of embedding 4: [0.02638990990817547, -0.021764595061540604, -0.00402186531573534, -0.03565401956439018, -0.002044644905254245]\n",
      "First five dimensions of embedding 5: [0.021542495116591454, -0.038422368466854095, -0.03157598525285721, -0.03854040801525116, -0.010291705839335918]\n",
      "Total number of dimensions in each embedding: [1536, 1536, 1536, 1536, 1536]\n",
      "========================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Create embeddings for multiple words using the text-embedding-3-small model\n",
    "\n",
    "# Define the inputs using an array of strings\n",
    "inputs = [\"Mary\", \"had\", \"a\", \"little\", \"lamb\"]  # This is an array of strings\n",
    "\n",
    "# Send the request to the model\n",
    "response_small = client.embeddings.create(\n",
    "    input=inputs,\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "# Capture the embeddings from the response\n",
    "embeddings_small = [item.embedding for item in response_small.data]\n",
    "\n",
    "# Iterate through the embeddings and print the first five elements for each\n",
    "print(\"========================================\")\n",
    "for i, embedding in enumerate(embeddings_small):\n",
    "    print(f\"First five dimensions of embedding {i+1}: {embedding[:5]}\")\n",
    "\n",
    "# Get the count of all elements in each embedding list\n",
    "counts_small = [len(embedding) for embedding in embeddings_small]\n",
    "print(\"Total number of dimensions in each embedding:\", counts_small)\n",
    "print(\"========================================\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoding_format (string)\n",
    "The format to return the embeddings in. Can be either float or base64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= FLOAT ===========================\n",
      "First five elements of embedding 1: [0.05237387, 0.008488261, -0.028862454, 0.037338875, -0.058482576]\n",
      "Total number of elements in each embedding: [1536]\n",
      "========================================\n",
      "\n",
      "\n",
      "=============== BASE64 =========================\n",
      "Base64 encoded embedding 1: /IVWPVkSCzz0cOy8pvAYPW2Lb72gYKG8tIw1PbyhnzyyB0O7BU8QvbpCRTt1oFk7iVmFv...\n",
      "Total number of elements in each base64-encoded embedding: [1536]\n",
      "========================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# simple example of how to use the OpenAI Python client to create embeddings for multiple words using the text-embedding-3-small model and base64 encoding\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Define the inputs using an array of strings\n",
    "inputs = \"Mary\"\n",
    "\n",
    "# Send the request to the model\n",
    "response_small = client.embeddings.create(\n",
    "    input=inputs,\n",
    "    model=\"text-embedding-3-small\",\n",
    "    encoding_format=\"float\",\n",
    ")\n",
    "\n",
    "# Capture the embeddings from the response\n",
    "embeddings_small = [item.embedding for item in response_small.data]\n",
    "\n",
    "# Print the first five elements for each embedding\n",
    "print(\"============= FLOAT ===========================\")\n",
    "for i, embedding in enumerate(embeddings_small):\n",
    "    print(f\"First five elements of embedding {i+1}: {embedding[:5]}\")\n",
    "\n",
    "# Get the count of all elements in each embedding list\n",
    "counts_small = [len(embedding) for embedding in embeddings_small]\n",
    "print(\"Total number of elements in each embedding:\", counts_small)\n",
    "print(\"========================================\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Send the request to the model for base64 encoded embeddings\n",
    "response_base64 = client.embeddings.create(\n",
    "    input=inputs,\n",
    "    model=\"text-embedding-3-small\",\n",
    "    encoding_format=\"base64\",\n",
    ")\n",
    "\n",
    "# Capture the base64-encoded embeddings from the response\n",
    "embeddings_base64 = [item.embedding for item in response_base64.data]\n",
    "\n",
    "# Print the first 69 characters of each base64-encoded embedding (to keep the output concise)\n",
    "print(\"=============== BASE64 =========================\")\n",
    "for i, embedding in enumerate(embeddings_base64):\n",
    "    print(f\"Base64 encoded embedding {i+1}: {embedding[:69]}...\")  # Truncated for brevity\n",
    "\n",
    "# Get the count of all elements in each base64-encoded embedding\n",
    "# Here we assume each base64 character represents one byte, and 4 base64 characters represent 3 bytes (24 bits)\n",
    "counts_base64 = [len(base64.b64decode(embedding)) // 4 for embedding in embeddings_base64]\n",
    "print(\"Total number of elements in each base64-encoded embedding:\", counts_base64)\n",
    "print(\"========================================\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= FLOAT ===========================\n",
      "First five elements of embedding 1: [0.05237387, 0.008488261, -0.028862454, 0.037338875, -0.058482576]\n",
      "First five elements of embedding 2: [-0.016156575, -0.00031287363, 0.0122825, 0.018016132, 0.056595176]\n",
      "First five elements of embedding 3: [0.026696905, 0.008715566, -0.009066422, 0.026457686, -0.0144568365]\n",
      "First five elements of embedding 4: [0.02638991, -0.021764595, -0.0040218653, -0.03565402, -0.002044645]\n",
      "First five elements of embedding 5: [0.021542495, -0.03842237, -0.031575985, -0.038540408, -0.010291706]\n",
      "Total number of elements in each embedding: [1536, 1536, 1536, 1536, 1536]\n",
      "========================================\n",
      "\n",
      "\n",
      "=============== BASE64 =========================\n",
      "Base64 encoded embedding 1: /IVWPVkSCzz0cOy8pvAYPW2Lb72gYKG8tIw1PbyhnzyyB0O7BU8QvbpCRTt1oFk7iVmFv...\n",
      "Base64 encoded embedding 2: y1qEvDAJpLmKPEk8kZaTPFjQZz1D2vK8hef7vGzrAj2OeKW8Z6CvvB8q5TwPeka8OGutP...\n",
      "Base64 encoded embedding 3: eLPaPLzLDjxUixS8yr3YPF7cbLwZKTQ8dOkFvO6+CrzV5xw6TgQRvQnBqjy5Kh29NugCv...\n",
      "Base64 encoded embedding 4: py/YPKpLsrzayYO78wkSvXP/BbvW1Q69t/8rvF/IBD3sbPu8RL6xvBT1DL3o3Wg8/VFnv...\n",
      "Base64 encoded embedding 5: 43mwPMZgHb3SVQG9jNwdvYueKLwUinA8fqnEvDxacjzxIXW7INZnPFfAJLzOmyE74Tu7v...\n",
      "Total number of elements in each base64-encoded embedding: [1536, 1536, 1536, 1536, 1536]\n",
      "========================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# simple example of how to use the OpenAI Python client to create embeddings for multiple words using the text-embedding-3-small model and base64 encoding\n",
    "# with an array of words\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Define the inputs using an array of strings\n",
    "inputs = [\"Mary\", \"had\", \"a\", \"little\", \"lamb\"]\n",
    "\n",
    "# Send the request to the model\n",
    "response_small = client.embeddings.create(\n",
    "    input=inputs,\n",
    "    model=\"text-embedding-3-small\",\n",
    "    encoding_format=\"float\",\n",
    ")\n",
    "\n",
    "# Capture the embeddings from the response\n",
    "embeddings_small = [item.embedding for item in response_small.data]\n",
    "\n",
    "# Print the first five elements for each embedding\n",
    "print(\"============= FLOAT ===========================\")\n",
    "for i, embedding in enumerate(embeddings_small):\n",
    "    print(f\"First five elements of embedding {i+1}: {embedding[:5]}\")\n",
    "\n",
    "# Get the count of all elements in each embedding list\n",
    "counts_small = [len(embedding) for embedding in embeddings_small]\n",
    "print(\"Total number of elements in each embedding:\", counts_small)\n",
    "print(\"========================================\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Send the request to the model for base64 encoded embeddings\n",
    "response_base64 = client.embeddings.create(\n",
    "    input=inputs,\n",
    "    model=\"text-embedding-3-small\",\n",
    "    encoding_format=\"base64\",\n",
    ")\n",
    "\n",
    "# Capture the base64-encoded embeddings from the response\n",
    "embeddings_base64 = [item.embedding for item in response_base64.data]\n",
    "\n",
    "# Print the first 69 characters of each base64-encoded embedding (to keep the output concise)\n",
    "print(\"=============== BASE64 =========================\")\n",
    "for i, embedding in enumerate(embeddings_base64):\n",
    "    print(f\"Base64 encoded embedding {i+1}: {embedding[:69]}...\")  # Truncated for brevity\n",
    "\n",
    "# Get the count of all elements in each base64-encoded embedding\n",
    "# Here we assume each base64 character represents one byte, and 4 base64 characters represent 3 bytes (24 bits)\n",
    "counts_base64 = [len(base64.b64decode(embedding)) // 4 for embedding in embeddings_base64]\n",
    "print(\"Total number of elements in each base64-encoded embedding:\", counts_base64)\n",
    "print(\"========================================\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dimensions (integer)\n",
    "The number of dimensions the resulting output embeddings should have. Only supported in text-embedding-3 and later models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "First five elements of embedding 1: [-0.013418477, -0.032644805, 0.0105535295, 0.007328028, 0.015055589]\n",
      "First five elements of embedding 2: [-0.042218767, 0.038666658, 0.018102929, -0.00787991, -0.00126116]\n",
      "First five elements of embedding 3: [0.024440145, -0.0069485446, 0.004879169, 0.038805533, 0.042045657]\n",
      "First five elements of embedding 4: [-0.035309646, 0.032272745, 0.02000049, 0.0031955454, 0.022289496]\n",
      "First five elements of embedding 5: [-0.076653056, -0.0030676725, -0.0031094095, 0.059624344, -0.0002951405]\n",
      "Total number of elements in each embedding: [1024, 1024, 1024, 1024, 1024]\n",
      "========================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Define the inputs using an array of strings\n",
    "inputs = [\"Mary\", \"had\", \"a\", \"little\", \"lamb\"]\n",
    "\n",
    "# Send the request to the model\n",
    "response_small = client.embeddings.create(\n",
    "    input=inputs,\n",
    "    model=\"text-embedding-3-large\",\n",
    "    encoding_format=\"float\",\n",
    "    dimensions=1024,\n",
    ")\n",
    "\n",
    "# Capture the embeddings from the response\n",
    "embeddings_small = [item.embedding for item in response_small.data]\n",
    "\n",
    "# Print the first five elements for each embedding\n",
    "print(\"========================================\")\n",
    "for i, embedding in enumerate(embeddings_small):\n",
    "    print(f\"First five elements of embedding {i+1}: {embedding[:5]}\")\n",
    "\n",
    "# Get the count of all elements in each embedding list\n",
    "counts_small = [len(embedding) for embedding in embeddings_small]\n",
    "print(\"Total number of elements in each embedding:\", counts_small)\n",
    "print(\"========================================\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
