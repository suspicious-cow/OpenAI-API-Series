{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Part 3\n",
    "# Going Through the Use Cases\n",
    "Here we show some representative use cases. We will use the Amazon fine-food reviews dataset for the following examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries that aren't in the Python standard library\n",
    "\n",
    "# Numpy is used for numerical operations, essential for handling arrays which are\n",
    "# often used in data manipulations for AI and embeddings.\n",
    "%pip install numpy\n",
    "\n",
    "# Pandas is utilized for data manipulation and analysis; it provides data structures\n",
    "# and operations for manipulating numerical tables and time series, which is helpful\n",
    "# in preprocessing data for AI models.\n",
    "%pip install pandas\n",
    "\n",
    "# Scipy is a library used for scientific computing which includes modules for\n",
    "# optimization, linear algebra, integration, and statistics. It's often used in AI\n",
    "# for calculating distances and other operations that support embeddings.\n",
    "%pip install scipy\n",
    "\n",
    "# OpenAI's library is needed to interact with OpenAI's API, useful for accessing\n",
    "# various AI models and tools, potentially including those related to embeddings.\n",
    "%pip install openai\n",
    "\n",
    "# Tiktoken (assuming the library's name and availability are correct) might be a\n",
    "# specialized library for tokenization or similar tasks in NLP, which could be\n",
    "# relevant to preparing data for embedding-based AI models.\n",
    "%pip install tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from ast import literal_eval\n",
    "\n",
    "# Related third-party imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Local application/library specific imports\n",
    "from openai import OpenAI\n",
    "import tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the OpenAI client\n",
    "# This assumes you have set an environment variable called OPENAI_API_KEY\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see what trying to answer without using RAG looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You answer questions about Amazon fine food reviews.'},\n",
    "        {'role': 'user', 'content': 'What people hated their food?'},\n",
    "    ],\n",
    "    model='gpt-4-turbo',\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining the Embeddings\n",
    "The dataset contains a total of 568,454 food reviews Amazon users left up to October 2012. We will use a subset of 1,000 most recent reviews for illustration purposes. The reviews are in English and tend to be positive or negative. Each review has a ProductId, UserId, Score, review title (Summary) and review body (Text). For example:\n",
    "\n",
    "| PRODUCT ID  | USER ID        | SCORE | SUMMARY             | TEXT                                           |\n",
    "|-------------|----------------|-------|---------------------|------------------------------------------------|\n",
    "| B001E4KFG0  | A3SGXH7AUHU8GW | 5     | Good Quality Dog Food | I have bought several of the Vitality canned... |\n",
    "| B00813GRG4  | A1D87F6ZCVE5NK | 1     | Not as Advertised   | Product arrived labeled as Jumbo Salted Peanut... |\n",
    "\n",
    "\n",
    "\n",
    "We will combine the review summary and review text into a single combined text. The model will encode this combined text and output a single vector embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to get the file size\n",
    "def get_file_size(file_path):\n",
    "    \"\"\" Returns the size of the file in megabytes. \"\"\"\n",
    "    size_bytes = os.path.getsize(file_path)\n",
    "    size_mb = size_bytes / (1024 * 1024)  # Convert from bytes to megabytes\n",
    "    return size_mb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the path to the input data file\n",
    "input_data_path = \"./EmbeddingsDemoAssets/fine_food_reviews_1k.csv\"\n",
    "\n",
    "# Read the CSV file using pandas and set the first column as the index\n",
    "df = pd.read_csv(input_data_path, index_col=0)\n",
    "\n",
    "# Select only the relevant columns from the dataframe\n",
    "df = df[[\"Time\", \"ProductId\", \"UserId\", \"Score\", \"Summary\", \"Text\"]]\n",
    "\n",
    "# Drop rows with any missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Drop rows with any missing values\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Combine the 'Summary' and 'Text' columns into a new column with a formatted string\n",
    "df[\"combined\"] = (\n",
    "    \"Title: \" + df[\"Summary\"].str.strip() + \"; Content: \" + df[\"Text\"].str.strip()\n",
    ")\n",
    "\n",
    "# Display the first 5 rows of the modified dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Model Embedding\n",
    "Now let's embed using the small model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This can take a couple of minutes to run \n",
    "\n",
    "# main utility function to get the embeddings\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    # Replace newlines in the text with spaces for consistent formatting\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    # Request the embedding for the cleaned text and return the embedding\n",
    "    return client.embeddings.create(input=[text], model=model).data[0].embedding\n",
    "\n",
    "# Apply the `get_embedding` function to each entry in the 'combined' column and store the results\n",
    "df['embedding'] = df['combined'].apply(lambda x: get_embedding(x))\n",
    "\n",
    "# Save the dataframe with embeddings to a CSV file, omitting the index\n",
    "df.to_csv('./EmbeddingsDemoAssets/fine_food_reviews_with_embeddings_1k.csv', index=False)\n",
    "\n",
    "# Display the first 5 rows of the modified dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the size of the data file\n",
    "file_path = './EmbeddingsDemoAssets/fine_food_reviews_with_embeddings_1k.csv'\n",
    "size_mb = get_file_size(file_path)\n",
    "print(f\"The size of the file is {size_mb:.2f} MB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large Model Embedding\n",
    "Let's embed using the large model next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This can take several minutes to run\n",
    "\n",
    "# utility function to get the embeddings with reduced dimensions\n",
    "def get_embedding_large(text, model=\"text-embedding-3-large\"):\n",
    "    # Replace newlines in the text with spaces for consistent formatting\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    # Request the embedding for the cleaned text and return the embedding\n",
    "    return client.embeddings.create(input=[text], model=model).data[0].embedding\n",
    "\n",
    "# Apply the `get_embedding_large` function to each entry in the 'combined' column and store the results\n",
    "df['embedding'] = df['combined'].apply(lambda x: get_embedding_large(x))\n",
    "\n",
    "# Save the dataframe with embeddings to a CSV file, omitting the index\n",
    "df.to_csv('./EmbeddingsDemoAssets/fine_food_reviews_with_embeddings_large_1k.csv', index=False)\n",
    "\n",
    "# Display the first 5 rows of the modified dataframe\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the size of the data file\n",
    "file_path = './EmbeddingsDemoAssets/fine_food_reviews_with_embeddings_large_1k.csv'\n",
    "size_mb = get_file_size(file_path)\n",
    "print(f\"The size of the file is {size_mb:.2f} MB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data\n",
    "Here we show how to load the data into a dataframe from a CSV file to make it ready to be used again when needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df_load = pd.read_csv('./EmbeddingsDemoAssets/fine_food_reviews_with_embeddings_large_1k.csv')\n",
    "\n",
    "# Convert the string representation of embeddings in the 'embedding' column to numpy arrays\n",
    "# By converting the embeddings from string format to numpy arrays immediately after loading, \n",
    "# we ensure that the data is in a ready-to-use state for any subsequent analysis or processing steps.\n",
    "df_load['embedding'] = df_load['embedding'].apply(eval).apply(np.array)\n",
    "\n",
    "# Display the first 5 rows of the loaded dataframe\n",
    "df_load.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the Dimensions\n",
    "Using larger embeddings, for example storing them in a vector store for retrieval, generally costs more and consumes more compute, memory and storage than using smaller embeddings.\n",
    "\n",
    "Both of the new embedding models were trained with a technique that allows developers to trade-off performance and cost of using embeddings. Specifically, developers can shorten embeddings (i.e. remove some numbers from the end of the sequence) without the embedding losing its concept-representing properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the path to the input data file\n",
    "input_data_path = \"./EmbeddingsDemoAssets/fine_food_reviews_1k.csv\"\n",
    "\n",
    "# Read the CSV file using pandas and set the first column as the index\n",
    "df_reduced_dims = pd.read_csv(input_data_path, index_col=0)\n",
    "\n",
    "# Select only the relevant columns from the dataframe\n",
    "df_reduced_dims = df_reduced_dims[[\"Time\", \"ProductId\", \"UserId\", \"Score\", \"Summary\", \"Text\"]]\n",
    "\n",
    "# Drop rows with any missing values\n",
    "df_reduced_dims = df_reduced_dims.dropna()\n",
    "\n",
    "# Drop rows with any missing values\n",
    "df_reduced_dims = df_reduced_dims.drop_duplicates()\n",
    "\n",
    "# Combine the 'Summary' and 'Text' columns into a new column with a formatted string\n",
    "df_reduced_dims[\"combined\"] = (\n",
    "    \"Title: \" + df_reduced_dims.Summary.str.strip() + \"; Content: \" + df_reduced_dims.Text.str.strip()\n",
    ")\n",
    "\n",
    "# Display the first 5 rows of the modified dataframe\n",
    "df_reduced_dims.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This can take a couple of minutes to run\n",
    "\n",
    "# utility function to get the embeddings with reduced dimensions\n",
    "def get_embedding_reduced_dims(text, model=\"text-embedding-3-large\"):\n",
    "    # Replace newlines in the text with spaces for consistent formatting\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    # Request the embedding for the cleaned text and return the embedding\n",
    "    return client.embeddings.create(input=[text], model=model,dimensions=1024).data[0].embedding\n",
    "\n",
    "# Apply the `get_embedding_reduced_dims` function to each entry in the 'combined' column and store the results\n",
    "df_reduced_dims['embedding'] = df_reduced_dims['combined'].apply(lambda x: get_embedding_reduced_dims(x))\n",
    "\n",
    "# Save the dataframe with embeddings to a CSV file, omitting the index\n",
    "df_reduced_dims.to_csv('./EmbeddingsDemoAssets/fine_food_reviews_with_embeddings_reduced_dims_1k.csv', index=False)\n",
    "\n",
    "# Display the first 5 rows of the modified dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the size of the data file\n",
    "file_path = './EmbeddingsDemoAssets/fine_food_reviews_with_embeddings_reduced_dims_1k.csv'\n",
    "size_mb = get_file_size(file_path)\n",
    "print(f\"The size of the file is {size_mb:.2f} MB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4\n",
    "\n",
    "## Question Answering Using Embeddings-Based Search\n",
    "There are many common cases where the model is not trained on data which contains key facts and information you want to make accessible when generating responses to a user query. One way of solving this is to put additional information into the context window of the model. This is effective in many use cases but leads to higher token costs. The other way is to use RAG to obtain the information.\n",
    "\n",
    "First, let's load up the file with the (large) embeddings in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>combined</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1351123200</td>\n",
       "      <td>B003XPF9BO</td>\n",
       "      <td>A3R7JR3FMEBXQB</td>\n",
       "      <td>5</td>\n",
       "      <td>where does one  start...and stop... with a tre...</td>\n",
       "      <td>Wanted to save some to bring to my Chicago fam...</td>\n",
       "      <td>Title: where does one  start...and stop... wit...</td>\n",
       "      <td>[-0.01042067352682352, 0.006103187799453735, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1351123200</td>\n",
       "      <td>B003JK537S</td>\n",
       "      <td>A3JBPC3WFUT5ZP</td>\n",
       "      <td>1</td>\n",
       "      <td>Arrived in pieces</td>\n",
       "      <td>Not pleased at all. When I opened the box, mos...</td>\n",
       "      <td>Title: Arrived in pieces; Content: Not pleased...</td>\n",
       "      <td>[0.007291625719517469, -0.026603516191244125, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1351123200</td>\n",
       "      <td>B000JMBE7M</td>\n",
       "      <td>AQX1N6A51QOKG</td>\n",
       "      <td>4</td>\n",
       "      <td>It isn't blanc mange, but isn't bad . . .</td>\n",
       "      <td>I'm not sure that custard is really custard wi...</td>\n",
       "      <td>Title: It isn't blanc mange, but isn't bad . ....</td>\n",
       "      <td>[-0.0033920640125870705, 0.00576418312266469, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1351123200</td>\n",
       "      <td>B004AHGBX4</td>\n",
       "      <td>A2UY46X0OSNVUQ</td>\n",
       "      <td>3</td>\n",
       "      <td>These also have SALT and it's not sea salt.</td>\n",
       "      <td>I like the fact that you can see what you're g...</td>\n",
       "      <td>Title: These also have SALT and it's not sea s...</td>\n",
       "      <td>[0.011859823018312454, -0.012551761232316494, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1351123200</td>\n",
       "      <td>B001BORBHO</td>\n",
       "      <td>A1AFOYZ9HSM2CZ</td>\n",
       "      <td>5</td>\n",
       "      <td>Happy with the product</td>\n",
       "      <td>My dog was suffering with itchy skin.  He had ...</td>\n",
       "      <td>Title: Happy with the product; Content: My dog...</td>\n",
       "      <td>[-0.011923440732061863, 0.011218789964914322, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time   ProductId          UserId  Score  \\\n",
       "0  1351123200  B003XPF9BO  A3R7JR3FMEBXQB      5   \n",
       "1  1351123200  B003JK537S  A3JBPC3WFUT5ZP      1   \n",
       "2  1351123200  B000JMBE7M   AQX1N6A51QOKG      4   \n",
       "3  1351123200  B004AHGBX4  A2UY46X0OSNVUQ      3   \n",
       "4  1351123200  B001BORBHO  A1AFOYZ9HSM2CZ      5   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  where does one  start...and stop... with a tre...   \n",
       "1                                  Arrived in pieces   \n",
       "2          It isn't blanc mange, but isn't bad . . .   \n",
       "3        These also have SALT and it's not sea salt.   \n",
       "4                             Happy with the product   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Wanted to save some to bring to my Chicago fam...   \n",
       "1  Not pleased at all. When I opened the box, mos...   \n",
       "2  I'm not sure that custard is really custard wi...   \n",
       "3  I like the fact that you can see what you're g...   \n",
       "4  My dog was suffering with itchy skin.  He had ...   \n",
       "\n",
       "                                            combined  \\\n",
       "0  Title: where does one  start...and stop... wit...   \n",
       "1  Title: Arrived in pieces; Content: Not pleased...   \n",
       "2  Title: It isn't blanc mange, but isn't bad . ....   \n",
       "3  Title: These also have SALT and it's not sea s...   \n",
       "4  Title: Happy with the product; Content: My dog...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.01042067352682352, 0.006103187799453735, -...  \n",
       "1  [0.007291625719517469, -0.026603516191244125, ...  \n",
       "2  [-0.0033920640125870705, 0.00576418312266469, ...  \n",
       "3  [0.011859823018312454, -0.012551761232316494, ...  \n",
       "4  [-0.011923440732061863, 0.011218789964914322, ...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df_search = pd.read_csv('./EmbeddingsDemoAssets/fine_food_reviews_with_embeddings_large_1k.csv')\n",
    "\n",
    "# Convert the string representation of embeddings in the 'embedding' column to numpy arrays\n",
    "# By converting the embeddings from string format to numpy arrays immediately after loading, \n",
    "# we ensure that the data is in a ready-to-use state for any subsequent analysis or processing steps.\n",
    "df_search['embedding'] = df_search['embedding'].apply(eval).apply(np.array)\n",
    "\n",
    "# Display the first 5 rows of the loaded dataframe\n",
    "df_search.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relatedness\n",
    "Now let's write some code to show the related reviews based on a ranking score. In this case, we will set up a function to take in our query string and compute the relateness scores for reviews. Then it will show us the top 5 reviews in terms of relatedness score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function that ranks strings from a pandas DataFrame based on their relatedness to a given query string.\n",
    "def strings_ranked_by_relatedness(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    relatedness_fn=lambda x, y: 1 - distance.cosine(x, y), # use cosine similarity as the relatedness function\n",
    "    top_n: int = 100,\n",
    "    threshold: float = 0.001  # Minimum score difference to consider for ranking\n",
    ") -> tuple[list[str], list[float]]:\n",
    "    \"\"\"\n",
    "    Retrieve the top 'n' strings related to a query string from a DataFrame, based on a custom relatedness function.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The string to compare other strings against.\n",
    "    df (pd.DataFrame): DataFrame containing the strings and their embeddings.\n",
    "    relatedness_fn (callable): A function that computes the relatedness score between two embeddings. By default, \n",
    "                               it uses the cosine similarity between embeddings.\n",
    "    top_n (int): The number of top related strings to return.\n",
    "    threshold (float): The minimum difference between scores needed to consider one string more related than another.\n",
    "\n",
    "    Returns:\n",
    "    tuple[list[str], list[float]]: A tuple containing two lists:\n",
    "                                   1. The top 'n' strings most related to the query.\n",
    "                                   2. Their corresponding relatedness scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the embedding for the query string using the large model.\n",
    "    query_embedding_response = client.embeddings.create(\n",
    "        model=\"text-embedding-3-large\",\n",
    "        input=query,\n",
    "    )\n",
    "    # Extract the embedding data from the response.\n",
    "    query_embedding = query_embedding_response.data[0].embedding\n",
    "\n",
    "    # Compute the relatedness of each string in the DataFrame to the query string.\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"combined\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # Sort the list of tuples by the relatedness score in descending order (most related first).\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Initialize a list to store the filtered results and a variable to track the last accepted score.\n",
    "    filtered = []\n",
    "    last_score = -1\n",
    "\n",
    "    # Filter strings to meet the threshold criteria and limit the number of results to 'top_n'.\n",
    "    for item in strings_and_relatednesses:\n",
    "        if abs(item[1] - last_score) > threshold:\n",
    "            filtered.append(item)\n",
    "            last_score = item[1]\n",
    "        if len(filtered) >= top_n:\n",
    "            break\n",
    "\n",
    "    # Unzip the tuples to separate strings and their relatedness scores.\n",
    "    strings, relatednesses = zip(*filtered)\n",
    "\n",
    "    # Return only the top 'n' results as specified by the function arguments.\n",
    "    return strings[:top_n], relatednesses[:top_n]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "relatedness=0.658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Title: Don't like the taste; Content: I do not like sour taste and this has a sour kind of taste which i don't like. The smell isn't that great either\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "relatedness=0.493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Title: Doesn't taste good...; Content: I didn't like the flavor of this root beer snow cone syrup, it has a bitter flavor.<br /><br />It is a great deal tho so it's too bad it doesn't taste good. :(\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "relatedness=0.472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Title: No Thanks!; Content: I LOVE the Blue Sky Wild Raspberry but I cannot stand the Black Cherry.  It doesn't have much flavor and it has an awful aftertaste.  UGH!\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "relatedness=0.452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Title: Didn't like it; Content: Quite personally, I didn't like it.  For me, it had no flavour at all.  It only tasted better when I added some nutmeg (ran out of cinnamon) and milk.  On the brightside, it did help me get rid of my cold :')\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "relatedness=0.444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Title: I did not like it.; Content: I did not like the taste of this Illy cappuccino drink.  I like coffee and coffee drinks in general, and I was looking forward to trying something new, but this product had a slight metallic/chemical aftertaste that, while not strong, was present in sufficient strength to make it less than pleasing to me.  I much prefer the Starbucks Mocha Cappuccino drink that tastes only of coffee, milk, sugar and chocolate.  I do not know if it is the metal container that imparts the aftertaste to the Illy product.  The similar Starbucks drink comes in a glass container that I suppose could have something to do with its fresher taste.  Also, since my opinion is certainly subjective, others may like the Illy drink and be just as justified in their opinion.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This code performs a search to find the top 5 items related to the phrase \"don't like the taste\" \n",
    "# from a DataFrame 'df_search' using the previously defined 'strings_ranked_by_relatedness' function.\n",
    "\n",
    "# Call the function 'strings_ranked_by_relatedness' with the query string, DataFrame, and specify the number \n",
    "# of top related items to return (top_n=5).\n",
    "strings, relatednesses = strings_ranked_by_relatedness(\"don't like the taste\", df_search, top_n=5)\n",
    "\n",
    "# Loop over each string and its corresponding relatedness score.\n",
    "# The 'zip' function combines the two lists 'strings' and 'relatednesses' so that items from both lists \n",
    "# can be accessed in a single loop iteration.\n",
    "for string, relatedness in zip(strings, relatednesses):\n",
    "    # Print a formatted string that includes a visual separator and the relatedness score formatted to three decimal places.\n",
    "    print(f\"\\n========================\\n{relatedness=:.3f}\")\n",
    "    \n",
    "    # The 'display' function is typically used in Jupyter Notebooks or similar environments to render objects in a more\n",
    "    # visually appealing manner than the basic print function. Here, it is used to display the string from the DataFrame.\n",
    "    display(string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asking Questions\n",
    "Now that we have the ability to find reviews that are relevant we can ask questions based on the reviews retrieved and put into the context window. We will need a number of items to make sure we are getting good data and that we don't go over our token limit of 128k.\n",
    "\n",
    "Let's start with a function to get a token count for any string passed into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def num_tokens(text: str, model: str = 'gpt-4-turbo') -> int:\n",
    "    \"\"\"\n",
    "    Return the number of tokens in a string using a specified model's tokenizer.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The input text to tokenize.\n",
    "        model (str): The model whose tokenizer is used, defaulting to 'gpt-4-turbo'.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of tokens that the text is divided into by the tokenizer.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the tokenizer configuration specific to the model\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "\n",
    "    # Encode the text using the tokenizer and count the number of tokens\n",
    "    return len(encoding.encode(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create a function to pull reviews from our dataframe that can be put into the GPT context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_message(query: str, df: pd.DataFrame, model: str, token_budget: int) -> str:\n",
    "    \"\"\"\n",
    "    Construct a message for GPT using related texts from a DataFrame, staying within a token limit.\n",
    "\n",
    "    Parameters:\n",
    "        query (str): The user's query to find related text.\n",
    "        df (pd.DataFrame): DataFrame containing potential related texts.\n",
    "        model (str): Model identifier for tokenization.\n",
    "        token_budget (int): Maximum number of tokens allowed in the final message.\n",
    "\n",
    "    Returns:\n",
    "        str: A message constructed with introductory text, relevant reviews, and the query.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve ranked strings and their relatedness from the dataframe\n",
    "    strings, relatednesses = strings_ranked_by_relatedness(query, df)\n",
    "\n",
    "    # Introduction to include in the message\n",
    "    introduction = 'Use the below Amazon food reviews to answer the subsequent question. If the answer cannot be found in the reviews, write \"I could not find an answer.\"'\n",
    "\n",
    "    # Formatting the query into a question format\n",
    "    question = f\"\\n\\nQuestion: {query}\"\n",
    "\n",
    "    # Initialize the message with the introduction text\n",
    "    message = introduction\n",
    "\n",
    "    # Iterate over each related string to build the message\n",
    "    for string in strings:\n",
    "        # Format the string as an Amazon Food Review\n",
    "        next_article = f'\\n\\nAmazon Food Review:\\n\"\"\"\\n{string}\\n\"\"\"'\n",
    "\n",
    "        # Check if adding the next article exceeds the token budget\n",
    "        if num_tokens(message + next_article + question, model=model) > token_budget:\n",
    "            break  # Stop adding articles if token budget is exceeded\n",
    "        else:\n",
    "            message += next_article  # Append the article if within budget\n",
    "\n",
    "    # Return the final message with the question appended\n",
    "    return message + question\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a function to actually allow us to ask questions from the GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    model: str = 'gpt-4-turbo',\n",
    "    token_budget: int = 4096 - 500,\n",
    "    print_message: bool = False\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate an answer to a query using GPT, based on a DataFrame of related texts.\n",
    "\n",
    "    Parameters:\n",
    "        query (str): The query to be answered.\n",
    "        df (pd.DataFrame): DataFrame containing texts and embeddings.\n",
    "        model (str): Model identifier for tokenization, default is 'gpt-4-turbo'.\n",
    "        token_budget (int): Maximum number of tokens for the generated message, default is 3596.\n",
    "        print_message (bool): Whether to print the constructed message, default is False.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response from GPT based on the query and provided texts.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate a message using related texts from the DataFrame\n",
    "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
    "\n",
    "    # Optionally print the constructed message\n",
    "    if print_message:\n",
    "        print(message)\n",
    "\n",
    "    # Set up the conversation format for the GPT model\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You answer questions about Amazon Food Reviews.\"},\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ]\n",
    "\n",
    "    # Request a completion from the GPT model\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0  # Use deterministic mode for reproducibility\n",
    "    )\n",
    "\n",
    "    # Extract the response message from the completion\n",
    "    response_message = response.choices[0].message.content\n",
    "\n",
    "    return response_message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's ask our question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Title: Inedible; Content: I am one of the least picky eaters that I know, but I had to throw my bowl out after a few spoons of this. It was disgusting and inedible. I wonder if anyone at these big companies try their products before marketing them. The flavor was heavily artificial with strong off-notes of bitterness and tree bark. Dont believe me? Go ahead and try it.\\n\\nTitle: God Awful; Content: As a dabbler who enjoys spanning the entire spectrum of taste, I am more than willing to try anything once. Both as a food aficionado and a lover of bacon, I just had to pick this up. One taste caused me to throw out my sandwich, and subsequently throw out the entire jar of unused mayonnaise. I would give this less than 1 star, if I could. Steer clear from this unless you're a major tool who has no sensibility past buying bacon-everything.\\n\\nTitle: Yuk! And who goes to Amazon to buy cereal?????; Content: This stuff tasted like (insert favorite negative adjective that Amazon won't print). I like most cereals but I couldn't put this stuff down, tasted like cardboard something with a half stale texture. Hate to throw 3/4 box of cereal away, we'll see if the birds will eat it - I have my doubts.\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit our question to the model\n",
    "ask(\"What are the top 3 reviews that indicate people don't like the food? Give me the title and text of the reviews in this format: Title: <title>; Content: <content>\",df_search)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output looks funky so let's pretty it up a bit. We can always try a variety of techniques, like outputting JSON, but, for now, we will just use regular expressions to deal with the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Title: **Inedible**\n",
      "   Content: I am one of the least picky eaters that I know, but I had to throw my bowl out after a few spoons of this. It was disgusting and inedible. I wonder if anyone at these big companies try their products before marketing them. The flavor was heavily artificial with strong off-notes of bitterness and tree bark. Dont believe me? Go ahead and try it.\n",
      "\n",
      "2. Title: **God Awful**\n",
      "   Content: As a dabbler who enjoys spanning the entire spectrum of taste, I am more than willing to try anything once. Both as a food aficionado and a lover of bacon, I just had to pick this up. One taste caused me to throw out my sandwich, and subsequently throw out the entire jar of unused mayonnaise. I would give this less than 1 star, if I could. Steer clear from this unless you're a major tool who has no sensibility past buying bacon-everything.\n",
      "\n",
      "3. Title: **Yuk! And who goes to Amazon to buy cereal?????**\n",
      "   Content: This stuff tasted like (insert favorite negative adjective that Amazon won't print). I like most cereals but I couldn't put this stuff down, tasted like cardboard something with a half stale texture. Hate to throw 3/4 box of cereal away, we'll see if the birds will eat it - I have my doubts.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def format_response(response: str) -> str:\n",
    "    \"\"\"\n",
    "    Format a string containing multiple entries with titles and contents into a readable format.\n",
    "\n",
    "    Parameters:\n",
    "        response (str): The string response containing multiple formatted entries.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string where each entry is separated and clearly labeled.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compile a pattern to match entries formatted as \"Title: <title>; Content: <content>\"\n",
    "    pattern = re.compile(r\"Title: (.*?); Content: (.*?)(?=\\nTitle: |$)\", re.S)\n",
    "    \n",
    "    # Extract all matches using the pattern\n",
    "    matches = pattern.findall(response)\n",
    "    \n",
    "    # List to store formatted entries\n",
    "    formatted_lines = []\n",
    "    \n",
    "    # Format each match with proper numbering and formatting\n",
    "    for index, (title, content) in enumerate(matches, start=1):\n",
    "        # Strip and replace newline characters in content\n",
    "        content = content.strip().replace('\\n', ' ')\n",
    "        # Append formatted title and content to the list\n",
    "        formatted_lines.append(f\"{index}. Title: **{title.strip()}**\")\n",
    "        formatted_lines.append(f\"   Content: {content}\")\n",
    "        formatted_lines.append('')  # Blank line for separation\n",
    "\n",
    "    # Join all formatted lines into a single string\n",
    "    return '\\n'.join(formatted_lines)\n",
    "\n",
    "# Example usage with a provided function response\n",
    "response = ask(\"What are the top 3 reviews that indicate people don't like the food? Give me the title and text of the reviews in this format: Title: <title>; Content: <content>\",df_search)\n",
    "formatted_output = format_response(response)\n",
    "print(formatted_output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5\n",
    "## Semantic Search\n",
    "Now we will do straight searching for similarities using cosine similarity to determine how similar the words we are looking for are to words in the reviews.\n",
    "\n",
    "First let's load data into our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into our dataframe and turn the embeddings into numpy arrays\n",
    "df_semantic_search = pd.read_csv('./EmbeddingsDemoAssets/fine_food_reviews_with_embeddings_large_1k.csv')\n",
    "\n",
    "df_semantic_search[\"embedding\"] = df_semantic_search.embedding.apply(literal_eval).apply(np.array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "Cosine similarity is a measure used to determine how similar two vectors are irrespective of their size. It is particularly useful in high-dimensional spaces, as is common in data science and text analysis.\n",
    "\n",
    "The cosine similarity is calculated by taking the cosine of the angle between two vectors. This value ranges from -1 to 1:\n",
    "\n",
    "A cosine similarity of 1 means that the vectors are pointing in exactly the same direction, indicating perfect similarity.\n",
    "A cosine similarity of -1 indicates that the vectors are diametrically opposite, representing perfect dissimilarity.\n",
    "A cosine similarity of 0 means that the vectors are orthogonal (perpendicular) to each other, signifying no similarity in their orientation.\n",
    "\n",
    "\n",
    "<div style=\"text-align:left;\">\n",
    "\n",
    "The cosine similarity between two vectors \\( A \\) and \\( B \\) is defined as:\n",
    "\n",
    "$$ \\text{Cosine Similarity} = \\frac{A \\cdot B}{\\|A\\| \\|B\\|} $$\n",
    "\n",
    "where \\( A * B \\) is the dot product of vectors \\( A \\) and \\( B \\), and \\( \\|A\\| \\) and \\( \\|B\\| \\) are the norms (or magnitudes) of the vectors.\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "relatedness=0.658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Title: Don't like the taste; Content: I do not like sour taste and this has a sour kind of taste which i don't like. The smell isn't that great either\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "relatedness=0.493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Title: Doesn't taste good...; Content: I didn't like the flavor of this root beer snow cone syrup, it has a bitter flavor.<br /><br />It is a great deal tho so it's too bad it doesn't taste good. :(\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "relatedness=0.472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Title: No Thanks!; Content: I LOVE the Blue Sky Wild Raspberry but I cannot stand the Black Cherry.  It doesn't have much flavor and it has an awful aftertaste.  UGH!\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "relatedness=0.452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Title: Didn't like it; Content: Quite personally, I didn't like it.  For me, it had no flavour at all.  It only tasted better when I added some nutmeg (ran out of cinnamon) and milk.  On the brightside, it did help me get rid of my cold :')\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "relatedness=0.444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Title: I did not like it.; Content: I did not like the taste of this Illy cappuccino drink.  I like coffee and coffee drinks in general, and I was looking forward to trying something new, but this product had a slight metallic/chemical aftertaste that, while not strong, was present in sufficient strength to make it less than pleasing to me.  I much prefer the Starbucks Mocha Cappuccino drink that tastes only of coffee, milk, sugar and chocolate.  I do not know if it is the metal container that imparts the aftertaste to the Illy product.  The similar Starbucks drink comes in a glass container that I suppose could have something to do with its fresher taste.  Also, since my opinion is certainly subjective, others may like the Illy drink and be just as justified in their opinion.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This code performs a search to find the top 5 items related to the phrase \"don't like the taste\" \n",
    "# from a DataFrame 'df_search' using the previously defined 'strings_ranked_by_relatedness' function.\n",
    "\n",
    "# Call the function 'strings_ranked_by_relatedness' with the query string, DataFrame, and specify the number \n",
    "# of top related items to return (top_n=5).\n",
    "strings, relatednesses = strings_ranked_by_relatedness(\"don't like the taste\", df_semantic_search, top_n=5)\n",
    "\n",
    "# Loop over each string and its corresponding relatedness score.\n",
    "# The 'zip' function combines the two lists 'strings' and 'relatednesses' so that items from both lists \n",
    "# can be accessed in a single loop iteration.\n",
    "for string, relatedness in zip(strings, relatednesses):\n",
    "    # Print a formatted string that includes a visual separator and the relatedness score formatted to three decimal places.\n",
    "    print(f\"\\n========================\\n{relatedness=:.3f}\")\n",
    "    \n",
    "    # The 'display' function is typically used in Jupyter Notebooks or similar environments to render objects in a more\n",
    "    # visually appealing manner than the basic print function. Here, it is used to display the string from the DataFrame.\n",
    "    display(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Distance\n",
    "Euclidean distance is a measure of the true straight line distance between two points in Euclidean space. It's the way we commonly measure distance in everyday situations, like distance between two locations on a map or in physical space. The concept comes from Euclidean geometry and is applicable in various dimensions, though it's most easily visualized in two or three dimensions.\n",
    "\n",
    "For two points, the Euclidean distance formula in a 2D space is given by:\n",
    "For two points in a 2D space:\n",
    "$$ \\text{Distance} = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2} $$\n",
    "\n",
    "For points in a 3D space:\n",
    "$$ \\text{Distance} = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2 + (z_2 - z_1)^2} $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rank_strings_by_euclidean(query: str, df: pd.DataFrame, top_n: int = 100) -> tuple[list[str], list[float]]:\n",
    "    \"\"\"\n",
    "    Returns a list of strings and their relatedness scores sorted from most related to least.\n",
    "    The relatedness is determined using the Euclidean  distance.\n",
    "    \n",
    "    Parameters:\n",
    "        query (str): The query string to compare against dataframe strings.\n",
    "        df (pd.DataFrame): DataFrame containing strings and their embeddings.\n",
    "        top_n (int): The number of top related strings to return.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two lists; one for strings and one for their corresponding relatedness scores.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve the embedding for the query string from a model\n",
    "    query_embedding_response = client.embeddings.create(\n",
    "        model='text-embedding-3-large',\n",
    "        input=query,\n",
    "    )\n",
    "    # Extract the embedding from the response\n",
    "    query_embedding = query_embedding_response.data[0].embedding\n",
    "\n",
    "    # Function to calculate negative euclidean distance between two embeddings\n",
    "    def calculate_relatedness(x, y):\n",
    "        return -distance.euclidean(x, y)\n",
    "\n",
    "    # Create a list of tuples containing strings from the DataFrame and their relatedness to the query\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"combined\"], calculate_relatedness(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()  # Iterate over DataFrame rows\n",
    "    ]\n",
    "\n",
    "    # Sort the list of tuples by relatedness, descending\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Unzip the sorted list into two lists: one for strings and another for relatedness scores\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "\n",
    "    # Return the top N related strings and their scores\n",
    "    return strings[:top_n], relatednesses[:top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "relatedness=-0.826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Title: Don't like the taste; Content: I do not like sour taste and this has a sour kind of taste which i don't like. The smell isn't that great either\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "relatedness=-1.007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Title: Doesn't taste good...; Content: I didn't like the flavor of this root beer snow cone syrup, it has a bitter flavor.<br /><br />It is a great deal tho so it's too bad it doesn't taste good. :(\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "relatedness=-1.027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Title: No Thanks!; Content: I LOVE the Blue Sky Wild Raspberry but I cannot stand the Black Cherry.  It doesn't have much flavor and it has an awful aftertaste.  UGH!\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "relatedness=-1.047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Title: Didn't like it; Content: Quite personally, I didn't like it.  For me, it had no flavour at all.  It only tasted better when I added some nutmeg (ran out of cinnamon) and milk.  On the brightside, it did help me get rid of my cold :')\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "relatedness=-1.054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Title: I did not like it.; Content: I did not like the taste of this Illy cappuccino drink.  I like coffee and coffee drinks in general, and I was looking forward to trying something new, but this product had a slight metallic/chemical aftertaste that, while not strong, was present in sufficient strength to make it less than pleasing to me.  I much prefer the Starbucks Mocha Cappuccino drink that tastes only of coffee, milk, sugar and chocolate.  I do not know if it is the metal container that imparts the aftertaste to the Illy product.  The similar Starbucks drink comes in a glass container that I suppose could have something to do with its fresher taste.  Also, since my opinion is certainly subjective, others may like the Illy drink and be just as justified in their opinion.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This code performs a search to find the top 5 items related to the phrase \"don't like the taste\" \n",
    "# from a DataFrame 'df_search' using the previously defined 'strings_ranked_by_relatedness' function.\n",
    "\n",
    "# Call the function 'strings_ranked_by_relatedness_ed' with the query string, DataFrame, and specify the number \n",
    "# of top related items to return (top_n=5).\n",
    "strings, relatednesses = rank_strings_by_euclidean(\"don't like the taste\", df_semantic_search, top_n=5)\n",
    "\n",
    "# Loop over each string and its corresponding relatedness score.\n",
    "# The 'zip' function combines the two lists 'strings' and 'relatednesses' so that items from both lists \n",
    "# can be accessed in a single loop iteration.\n",
    "for string, relatedness in zip(strings, relatednesses):\n",
    "    # Print a formatted string that includes a visual separator and the relatedness score formatted to three decimal places.\n",
    "    print(f\"\\n========================\\n{relatedness=:.3f}\")\n",
    "    \n",
    "    # The 'display' function is typically used in Jupyter Notebooks or similar environments to render objects in a more\n",
    "    # visually appealing manner than the basic print function. Here, it is used to display the string from the DataFrame.\n",
    "    display(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation Example\n",
    "Because shorter distances between embedding vectors represent greater similarity, embeddings can be useful for recommendation.\n",
    "\n",
    "Below, we illustrate a basic recommender. It takes in a list of strings and one 'source' string, computes their embeddings, and then returns a ranking of the strings, ranked from most similar to least similar. As a concrete example, we apply a version of this function to the AG news dataset (sampled down to 2,000 news article descriptions) to return the top 5 most similar articles to any given source article.\n",
    "\n",
    "### Load the Data\n",
    "First, let's load our data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title: World Briefings\n",
      "Description: BRITAIN: BLAIR WARNS OF CLIMATE THREAT Prime Minister Tony Blair urged the international community to consider global warming a dire threat and agree on a plan of action to curb the  quot;alarming quot; growth of greenhouse gases.\n",
      "Label: World\n",
      "\n",
      "Title: Nvidia Puts a Firewall on a Motherboard (PC World)\n",
      "Description: PC World - Upcoming chip set will include built-in security features for your PC.\n",
      "Label: Sci/Tech\n",
      "\n",
      "Title: Olympic joy in Greek, Chinese press\n",
      "Description: Newspapers in Greece reflect a mixture of exhilaration that the Athens Olympics proved successful, and relief that they passed off without any major setback.\n",
      "Label: Sports\n",
      "\n",
      "Title: U2 Can iPod with Pictures\n",
      "Description: SAN JOSE, Calif. -- Apple Computer (Quote, Chart) unveiled a batch of new iPods, iTunes software and promos designed to keep it atop the heap of digital music players.\n",
      "Label: Sci/Tech\n",
      "\n",
      "Title: The Dream Factory\n",
      "Description: Any product, any shape, any size -- manufactured on your desktop! The future is the fabricator. By Bruce Sterling from Wired magazine.\n",
      "Label: Sci/Tech\n"
     ]
    }
   ],
   "source": [
    "# load data from dataset\n",
    "# full dataset available at http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html\n",
    "dataset_path = \"./EmbeddingsDemoAssets/AG_news_samples.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Number of examples to display\n",
    "n_examples = 5\n",
    "\n",
    "# Print the title, description, and label of the top n examples\n",
    "for idx, row in df.head(n_examples).iterrows():\n",
    "    print(\"\\nTitle:\", row['title'])\n",
    "    print(\"Description:\", row['description'])\n",
    "    print(\"Label:\", row['label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Cache to Save Embeddings\n",
    "Before getting embeddings, let's set up a cache to save the embeddings we generate. In general, it's a good idea to save your embeddings so you can re-use them later. If you don't save them, you'll pay again each time you compute them again.\n",
    "\n",
    "The cache is a dictionary that maps tuples of (text, model) to an embedding, which is a list of floats. The cache is saved as a Python pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the embedding cache file\n",
    "embedding_cache_path = \"./EmbeddingsDemoAssets/recommendations_embeddings_cache.pkl\"\n",
    "\n",
    "# Try to load the embedding cache if it exists, otherwise initialize an empty dictionary\n",
    "try:\n",
    "    with open(embedding_cache_path, \"rb\") as embedding_cache_file:\n",
    "        embedding_cache = pickle.load(embedding_cache_file)\n",
    "except FileNotFoundError:\n",
    "    embedding_cache = {}\n",
    "\n",
    "# Define a function to retrieve embeddings from the cache or request via the API if not found\n",
    "def embedding_from_string(string: str, model: str = \"text-embedding-3-large\", cache=embedding_cache) -> list:\n",
    "    \"\"\"\n",
    "    Retrieve the embedding of a given string using a specified model.\n",
    "    Utilizes a cache to avoid redundant API calls.\n",
    "\n",
    "    Parameters:\n",
    "        string (str): The string to embed.\n",
    "        model (str): The model to use for embedding.\n",
    "        cache (dict): The cache to store and retrieve embeddings.\n",
    "\n",
    "    Returns:\n",
    "        list: The embedding vector of the string.\n",
    "    \"\"\"\n",
    "    # Check if the embedding is already in the cache\n",
    "    if (string, model) not in cache:\n",
    "        # Assume get_embedding_large is a function that requests the embedding from an API\n",
    "        cache[(string, model)] = get_embedding_large(string, model)\n",
    "        # Save the updated cache to disk\n",
    "        with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "            pickle.dump(cache, embedding_cache_file)\n",
    "    return cache[(string, model)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure everything is working by getting an embeddding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example string: BRITAIN: BLAIR WARNS OF CLIMATE THREAT Prime Minister Tony Blair urged the international community to consider global warming a dire threat and agree on a plan of action to curb the  quot;alarming quot; growth of greenhouse gases.\n",
      "\n",
      "Example embedding: [0.007415562402456999, -0.014499394223093987, -0.002792066428810358, 0.00036477413959801197, -0.00924008060246706, -0.011810993775725365, 0.011520729400217533, 0.012778541073203087, -0.023718740791082382, 0.0015549873933196068]...\n",
      "\n",
      "Example string: The Microsoft CEO says one way to stem growing piracy of Windows and Office in emerging markets is to offer low-cost computers.\n",
      "\n",
      "Example embedding: [-0.018890535458922386, -0.012971138581633568, -0.021860403940081596, -0.01110649574548006, -0.056468188762664795, 0.0030105519108474255, -0.0035597742535173893, 0.029291855171322823, 0.02150781638920307, 0.02474890649318695]...\n"
     ]
    }
   ],
   "source": [
    "# Example usage: Retrieving and displaying embeddings for descriptions from the dataset\n",
    "\n",
    "# Fetch the first description from the dataset and print it\n",
    "example_string = df[\"description\"].iloc[0]  # Use iloc for safer access by index\n",
    "print(f\"\\nExample string: {example_string}\")\n",
    "\n",
    "# Retrieve the embedding for the first description and print the first 10 dimensions\n",
    "example_embedding = embedding_from_string(example_string)\n",
    "print(f\"\\nExample embedding: {example_embedding[:10]}...\")\n",
    "\n",
    "# Fetch the tenth description from the dataset and print it\n",
    "example_string_10 = df[\"description\"].iloc[9]  # Use iloc for safer access by index\n",
    "print(f\"\\nExample string: {example_string_10}\")\n",
    "\n",
    "# Retrieve the embedding for the tenth description and print the first 10 dimensions\n",
    "example_embedding_10 = embedding_from_string(example_string_10)\n",
    "print(f\"\\nExample embedding: {example_embedding_10[:10]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend Similar Articles Based on Embeddings\n",
    "To find similar articles, let's follow a three-step plan:\n",
    "\n",
    "1. Get the similarity embeddings of all the article descriptions\n",
    "2. Calculate the distance between a source title and all other articles\n",
    "3. Print out the other articles closest to the source title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def distances_from_embeddings(query_embedding, embeddings, distance_metric=\"cosine\"):\n",
    "    \"\"\"\n",
    "    Calculate distances from the query embedding to each embedding in the list.\n",
    "\n",
    "    Parameters:\n",
    "        query_embedding (array): The embedding of the query string.\n",
    "        embeddings (list of arrays): A list of embeddings to compare against.\n",
    "        distance_metric (str): The metric used to calculate distance, default is \"cosine\".\n",
    "\n",
    "    Returns:\n",
    "        list: Distances from the query embedding to each embedding in the list.\n",
    "    \"\"\"\n",
    "    distances = []\n",
    "    for emb in embeddings:\n",
    "        dist = distance.cosine(query_embedding, emb) if emb is not None else np.inf\n",
    "        distances.append(dist)\n",
    "    return distances\n",
    "\n",
    "def indices_of_nearest_neighbors_from_distances(distances, k=1):\n",
    "    \"\"\"\n",
    "    Return indices of the k nearest neighbors based on the given distances.\n",
    "\n",
    "    Parameters:\n",
    "        distances (list): List of distances from the query.\n",
    "        k (int): Number of nearest neighbors to return.\n",
    "\n",
    "    Returns:\n",
    "        array: Indices of the k nearest neighbors.\n",
    "    \"\"\"\n",
    "    sorted_indices = np.argsort(distances)\n",
    "    return sorted_indices[1:k+1]  # Skip the first index assuming it's the query itself\n",
    "\n",
    "def print_recommendations_from_strings(strings, index_of_source_string, model='text-embedding-3-large', k_nearest_neighbors=1):\n",
    "    \"\"\"\n",
    "    Print out the k nearest neighbors of a given string based on embeddings.\n",
    "\n",
    "    Parameters:\n",
    "        strings (list): List of strings to consider for neighbors.\n",
    "        index_of_source_string (int): Index of the string to find neighbors for.\n",
    "        model (str): Model used for generating embeddings.\n",
    "        k_nearest_neighbors (int): Number of nearest neighbors to print.\n",
    "\n",
    "    Returns:\n",
    "        list: Indices of the nearest neighbors.\n",
    "    \"\"\"\n",
    "    embeddings = [embedding_from_string(string, model=model) for string in strings]\n",
    "    query_embedding = embeddings[index_of_source_string]\n",
    "    distances = distances_from_embeddings(query_embedding, embeddings)\n",
    "    indices_of_nearest_neighbors = indices_of_nearest_neighbors_from_distances(distances, k_nearest_neighbors + 1)\n",
    "\n",
    "    query_string = strings[index_of_source_string]\n",
    "    print(f\"Source string: {query_string}\")\n",
    "    \n",
    "    # Filter out the source string index and print recommendations\n",
    "    recommendations = [i for i in indices_of_nearest_neighbors if i != index_of_source_string]\n",
    "    for idx, rec_idx in enumerate(recommendations[:k_nearest_neighbors], 1):\n",
    "        print(f\"\"\"\n",
    "        --- Recommendation #{idx} (Nearest Neighbor #{idx} of {k_nearest_neighbors}) ---\n",
    "        String: {strings[rec_idx]}\n",
    "        Distance: {distances[rec_idx]:0.3f}\n",
    "        \"\"\")\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source string: BRITAIN: BLAIR WARNS OF CLIMATE THREAT Prime Minister Tony Blair urged the international community to consider global warming a dire threat and agree on a plan of action to curb the  quot;alarming quot; growth of greenhouse gases.\n",
      "\n",
      "        --- Recommendation #1 (Nearest Neighbor #1 of 5) ---\n",
      "        String: THE re-election of British Prime Minister Tony Blair would be seen as an endorsement of the military action in Iraq, Prime Minister John Howard said today.\n",
      "        Distance: 0.520\n",
      "        \n",
      "\n",
      "        --- Recommendation #2 (Nearest Neighbor #2 of 5) ---\n",
      "        String: AP - Police defused a bomb in a town near Prime Minister Silvio Berlusconi's villa on the island of Sardinia on Wednesday shortly after British Prime Minister Tony Blair finished a visit there with the Italian leader.\n",
      "        Distance: 0.524\n",
      "        \n",
      "\n",
      "        --- Recommendation #3 (Nearest Neighbor #3 of 5) ---\n",
      "        String: Israel is prepared to back a Middle East conference convened by Tony Blair early next year despite having expressed fears that the British plans were over-ambitious and designed \n",
      "        Distance: 0.539\n",
      "        \n",
      "\n",
      "        --- Recommendation #4 (Nearest Neighbor #4 of 5) ---\n",
      "        String: The anguish of hostage Kenneth Bigley in Iraq hangs over Prime Minister Tony Blair today as he faces the twin test of a local election and a debate by his Labour Party about the divisive war.\n",
      "        Distance: 0.539\n",
      "        \n",
      "\n",
      "        --- Recommendation #5 (Nearest Neighbor #5 of 5) ---\n",
      "        String: AFP - A battle group of British troops rolled out of southern Iraq on a US-requested mission to deadlier areas near Baghdad, in a major political gamble for British Prime Minister Tony Blair.\n",
      "        Distance: 0.552\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# NOTE: This code block may take a few minutes to run\n",
    "article_descriptions = df[\"description\"].tolist()\n",
    "\n",
    "tony_blair_articles = print_recommendations_from_strings(\n",
    "    strings=article_descriptions,  # let's base similarity off of the article description\n",
    "    index_of_source_string=0,  # articles similar to the first one about Tony Blair\n",
    "    k_nearest_neighbors=5,  # 5 most similar articles\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source string: PC World - Upcoming chip set will include built-in security features for your PC.\n",
      "\n",
      "        --- Recommendation #1 (Nearest Neighbor #1 of 5) ---\n",
      "        String: PC World - Updated antivirus software for businesses adds intrusion prevention features.\n",
      "        Distance: 0.476\n",
      "        \n",
      "\n",
      "        --- Recommendation #2 (Nearest Neighbor #2 of 5) ---\n",
      "        String: Chips that help a computer's main microprocessors perform specific types of math problems are becoming a big business once again.\\\n",
      "        Distance: 0.512\n",
      "        \n",
      "\n",
      "        --- Recommendation #3 (Nearest Neighbor #3 of 5) ---\n",
      "        String: originally offered on notebook PCs -- to its Opteron 32- and 64-bit x86 processors for server applications. The technology will help servers to run \n",
      "        Distance: 0.526\n",
      "        \n",
      "\n",
      "        --- Recommendation #4 (Nearest Neighbor #4 of 5) ---\n",
      "        String: PC World - Symantec, McAfee hope raising virus-definition fees will move users to\\  suites.\n",
      "        Distance: 0.549\n",
      "        \n",
      "\n",
      "        --- Recommendation #5 (Nearest Neighbor #5 of 5) ---\n",
      "        String:  SAN FRANCISCO (Reuters) - Intel Corp. &lt;A HREF=\"http://www.reuters.co.uk/financeQuoteLookup.jhtml?ticker=INTC.O qtype=sym infotype=info qcat=news\"&gt;INTC.O&lt;/A&gt; on Thursday  outlined its vision of the Internet of the future, one in which  millions of computer servers would analyze and direct network  traffic to make the Web safer and more efficient.\n",
      "        Distance: 0.565\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# NOTE: This code block may take a few minutes to run\n",
    "chipset_security_articles = print_recommendations_from_strings(\n",
    "    strings=article_descriptions,  # let's base similarity off of the article description\n",
    "    index_of_source_string=1,  # let's look at articles similar to the second one about a more secure chipset\n",
    "    k_nearest_neighbors=5,  # let's look at the 5 most similar articles\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put The Results into JSON Format\n",
    "JSON is a popular structured format that is used worldwide for transmitting text information. Let's put our Tony Blair articles in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"title\": \"Blair win would endorse war: PM\",\n",
      "        \"description\": \"THE re-election of British Prime Minister Tony Blair would be seen as an endorsement of the military action in Iraq, Prime Minister John Howard said today.\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Bomb Found in Town Near Berlusconi Villa (AP)\",\n",
      "        \"description\": \"AP - Police defused a bomb in a town near Prime Minister Silvio Berlusconi's villa on the island of Sardinia on Wednesday shortly after British Prime Minister Tony Blair finished a visit there with the Italian leader.\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Sharon gives Blair #39;s Middle East summit an unexpected boost\",\n",
      "        \"description\": \"Israel is prepared to back a Middle East conference convened by Tony Blair early next year despite having expressed fears that the British plans were over-ambitious and designed \"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Blair faces vote amidst hostage crisis\",\n",
      "        \"description\": \"The anguish of hostage Kenneth Bigley in Iraq hangs over Prime Minister Tony Blair today as he faces the twin test of a local election and a debate by his Labour Party about the divisive war.\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"British troops in Iraq head north on risky mission (AFP)\",\n",
      "        \"description\": \"AFP - A battle group of British troops rolled out of southern Iraq on a US-requested mission to deadlier areas near Baghdad, in a major political gamble for British Prime Minister Tony Blair.\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \" #39;Sudden jump #39; in greenhouse gases\",\n",
      "        \"description\": \"LONDON, England -- A US scientist is reported to have observed a surprising jump in the amount of carbon dioxide, the main greenhouse gas.\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a list of dictionaries for each selected article, including available details\n",
    "articles_json = [\n",
    "    {\n",
    "        'title': df.loc[index, 'title'],\n",
    "        'description': df.loc[index, 'description']\n",
    "    } for index in tony_blair_articles\n",
    "]\n",
    "\n",
    "# Optionally convert to a JSON string if needed for file storage or transmission\n",
    "articles_json_string = json.dumps(articles_json, indent=4)\n",
    "\n",
    "print(articles_json_string)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
