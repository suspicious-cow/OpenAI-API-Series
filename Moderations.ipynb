{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moderations\n",
    "\n",
    "The moderations endpoint is a tool you can use to check whether text is potentially harmful. Developers can use it to identify content that might be harmful and take action, for instance by filtering it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Emperor Penguin\n",
      "2. Adélie Penguin\n",
      "3. Galápagos Penguin\n",
      "4. King Penguin\n",
      "5. Little Blue Penguin\n"
     ]
    }
   ],
   "source": [
    "# Without moderation\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    messages=[ \n",
    "    {\"role\": \"system\", \"content\": \"You are an expert in penguins.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Give me a list of 5 species of penguins in the world. Just give me the list and nothing else.\"}\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=256,\n",
    "    stop=None,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    ")\n",
    "\n",
    "# After getting just the content of the message\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any flags? False\n",
      "\n",
      "\n",
      "Moderation(categories=Categories(harassment=False, harassment_threatening=False, hate=False, hate_threatening=False, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, self-harm=False, sexual/minors=False, hate/threatening=False, violence/graphic=False, self-harm/intent=False, self-harm/instructions=False, harassment/threatening=False), category_scores=CategoryScores(harassment=0.0001835661823861301, harassment_threatening=3.993876816821285e-06, hate=2.735637463047169e-05, hate_threatening=1.2607359849425848e-06, self_harm=1.3413207398116356e-06, self_harm_instructions=1.6119014617288485e-05, self_harm_intent=1.414909365848871e-05, sexual=8.976996468845755e-06, sexual_minors=1.01416098914342e-05, violence=5.635781053570099e-05, violence_graphic=7.66711491451133e-06, self-harm=1.3413207398116356e-06, sexual/minors=1.01416098914342e-05, hate/threatening=1.2607359849425848e-06, violence/graphic=7.66711491451133e-06, self-harm/intent=1.414909365848871e-05, self-harm/instructions=1.6119014617288485e-05, harassment/threatening=3.993876816821285e-06), flagged=False)\n",
      "\n",
      "\n",
      "\n",
      "Categories(harassment=False, harassment_threatening=False, hate=False, hate_threatening=False, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, self-harm=False, sexual/minors=False, hate/threatening=False, violence/graphic=False, self-harm/intent=False, self-harm/instructions=False, harassment/threatening=False)\n",
      "\n",
      "\n",
      "\n",
      "CategoryScores(harassment=0.0001835661823861301, harassment_threatening=3.993876816821285e-06, hate=2.735637463047169e-05, hate_threatening=1.2607359849425848e-06, self_harm=1.3413207398116356e-06, self_harm_instructions=1.6119014617288485e-05, self_harm_intent=1.414909365848871e-05, sexual=8.976996468845755e-06, sexual_minors=1.01416098914342e-05, violence=5.635781053570099e-05, violence_graphic=7.66711491451133e-06, self-harm=1.3413207398116356e-06, sexual/minors=1.01416098914342e-05, hate/threatening=1.2607359849425848e-06, violence/graphic=7.66711491451133e-06, self-harm/intent=1.414909365848871e-05, self-harm/instructions=1.6119014617288485e-05, harassment/threatening=3.993876816821285e-06)\n",
      "\n",
      "\n",
      "\n",
      "Harassment flag: False\n",
      "\n",
      "\n",
      "\n",
      "Harassment score: 0.0001835661823861301\n",
      "\n",
      "\n",
      "\n",
      "Moderation check passed. Generating completion...\n",
      "\n",
      "1. Emperor Penguin\n",
      "2. Adélie Penguin\n",
      "3. King Penguin\n",
      "4. Little Blue Penguin\n",
      "5. Gentoo Penguin\n"
     ]
    }
   ],
   "source": [
    "# With moderation\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "user_prompt = \"Give me a list of 5 species of penguins in the world. Just give me the list and nothing else.\"\n",
    "# user_prompt = \"You are stupid!\"\n",
    "\n",
    "moderation_result = client.moderations.create(input=user_prompt)\n",
    "is_flagged = moderation_result.results[0].flagged\n",
    "\n",
    "print(f\"Any flags? {is_flagged}\\n\\n\")\n",
    "print(moderation_result.results[0])\n",
    "print(\"\\n\\n\")\n",
    "print(moderation_result.results[0].categories)\n",
    "print(\"\\n\\n\")\n",
    "print(moderation_result.results[0].category_scores)\n",
    "print(\"\\n\\n\")\n",
    "print(f\"Harassment flag: {moderation_result.results[0].categories.harassment}\")\n",
    "print(\"\\n\\n\")\n",
    "print(f\"Harassment score: {moderation_result.results[0].category_scores.harassment}\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "if is_flagged:\n",
    "    print(\"Your prompt was flagged for moderation.\")\n",
    "else:\n",
    "    print(\"Moderation check passed. Generating completion...\\n\")\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        messages=[ \n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=1,\n",
    "        max_tokens=256,\n",
    "        stop=None,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "    )\n",
    "    print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your prompt was flagged for moderation. I am unable to process your request.\n"
     ]
    }
   ],
   "source": [
    "# With moderation (cleaned up)\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Define the user prompt that will be checked for moderation and possibly processed\n",
    "user_prompt = \"You are stupid!\"\n",
    "\n",
    "# Use the OpenAI API to check if the user prompt contains any content that needs moderation\n",
    "moderation_result = client.moderations.create(input=user_prompt)\n",
    "\n",
    "# Extract the flagged status from the moderation result to determine if the content is appropriate\n",
    "is_flagged = moderation_result.results[0].flagged\n",
    "\n",
    "# Check if the content was flagged by the moderation tool\n",
    "if is_flagged:\n",
    "    # If flagged, print a message indicating that the content cannot be processed\n",
    "    print(\"Your prompt was flagged for moderation. I am unable to process your request.\")\n",
    "else:\n",
    "    # If not flagged, proceed to generate a response \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=1,  \n",
    "        max_tokens=256,  \n",
    "        stop=None,  \n",
    "        top_p=1,  \n",
    "        frequency_penalty=0,  \n",
    "        presence_penalty=0,  \n",
    "    )\n",
    "    # Print the generated content from the chat completion\n",
    "    print(completion.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
